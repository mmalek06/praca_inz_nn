{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "The previous notebook (inception_resnet_v2_self_trained_on_200x150) created \"baseline models\" that I can improve on. For example I haven’t used the tabular data and neither have I used any image augmentation. Also, the original architecture likes square images, but I’m giving it rectangular ones. ROI detection net will have to be trained to enable the possibility to detect the main location of the lesion and crop the image accordingly. Both of these points will be addressed next, and this notebook is about improving the results by using tabular data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "metadata_path = os.path.join('..', 'data', 'HAM10000_metadata.csv')\n",
    "data = pd.read_csv(metadata_path)\n",
    "data['age'] = data.groupby('sex')['age'].transform(lambda x: x.fillna(x.mean()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "get_names = lambda root_path: [\n",
    "    file_name.split('.')[0]\n",
    "    for dir_path, _, file_names in os.walk(root_path)\n",
    "    for file_name in file_names\n",
    "]\n",
    "train_dir = os.path.join('..', 'data', 'images_original_inception_resnet_v2_200x150_categorized', 'training')\n",
    "valid_dir = os.path.join('..', 'data', 'images_original_inception_resnet_v2_200x150_categorized', 'validation')\n",
    "train_names = set(get_names(train_dir))\n",
    "valid_names = set(get_names(valid_dir))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8015 images belonging to 7 classes.\n",
      "Found 2000 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 200),\n",
    "    batch_size=64,\n",
    "    class_mode=None) # setting this param to None because the labels will be taken care of separately\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=(150, 200),\n",
    "    batch_size=64,\n",
    "    class_mode=None)\n",
    "train_df = data[data['image_id'].isin(train_names)][['dx', 'age', 'sex']]\n",
    "valid_df = data[data['image_id'].isin(valid_names)][['dx', 'age', 'sex']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "train_age = np.expand_dims(train_df['age'].astype(int).to_numpy(), -1)\n",
    "train_sex_categories = pd.get_dummies(train_df['sex']).to_numpy()\n",
    "valid_age = np.expand_dims(valid_df['age'].astype(int).to_numpy(), -1)\n",
    "valid_sex_categories = pd.get_dummies(valid_df['sex']).to_numpy()\n",
    "X_train = np.hstack((train_age, train_sex_categories))\n",
    "y_train = pd.get_dummies(train_df['dx'])\n",
    "X_valid = np.hstack((valid_age, valid_sex_categories))\n",
    "y_valid = pd.get_dummies(valid_df['dx'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The model I build in this notebook will be a multi input one, which means that in order for image data and tabular data play well together, some customizations need to be made: the MultipleInputGenerator class. Sadly, the types were not easy to find, for example I'm not sure what types x_set, y_set are, and so I decided to not use them here at all."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "class MultipleInputGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(self.x[0].shape[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.x[0].shape[0] / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_x = [x[indices] for x in self.x]\n",
    "        batch_y = self.y[indices]\n",
    "\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "SMALLER_WIDTH = 600 // 3\n",
    "SMALLER_HEIGHT = 450 // 3\n",
    "\n",
    "\n",
    "def get_model() -> keras.Model:\n",
    "    base_model = InceptionResNetV2(include_top=False, weights=None, input_shape=(SMALLER_HEIGHT, SMALLER_WIDTH, 3))\n",
    "    img_x = base_model.output\n",
    "    img_x = keras.layers.Dropout(.4)(img_x)\n",
    "    img_x = keras.layers.GlobalAveragePooling2D()(img_x)\n",
    "    img_x = keras.layers.Dense(512)(img_x)\n",
    "    img_x = keras.layers.PReLU()(img_x)\n",
    "    img_x = keras.layers.Dropout(.4)(img_x)\n",
    "    img_x = keras.layers.Dense(512)(img_x)\n",
    "    img_x = keras.layers.PReLU()(img_x)\n",
    "    predictions = keras.layers.Dense(7, activation='softmax')(img_x)\n",
    "    model = keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_model(model_factory, model_name: str) -> None:\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,\n",
    "                                                   min_delta=1e-6)\n",
    "    model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath='models/' + model_name + '{epoch}',\n",
    "        save_best_only=True)\n",
    "    tensor_board = keras.callbacks.TensorBoard(log_dir=f'tensor_logs/{model_name}')\n",
    "    model = model_factory()\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        validation_data=valid_generator,\n",
    "        epochs=50,\n",
    "        callbacks=[early_stopping, model_checkpoint, tensor_board])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
