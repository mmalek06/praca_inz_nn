{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h3>This notebook contains training code of a neural network performing the \"Region of Interest\" (ROI) detection work. Its output will be used at later stages to preprocess images being fed to the actual classifier. ROI NN will detect bounding boxes surrounding lesions and another algorithm will crop the images so that the aspect ratio required by InceptionResNetV2 NN is used.</h3>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import absl.logging\n",
    "import PIL.Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from typing import Callable\n",
    "from tensorflow import keras\n",
    "\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "get_names = lambda root_path: [\n",
    "    file_name.split('.')[0]\n",
    "    for dir_path, _, file_names in os.walk(root_path)\n",
    "    for file_name in file_names\n",
    "]\n",
    "get_paths = lambda path: [f'{os.path.join(root, file)}' for root, dirs, files in os.walk(path) for file in files]\n",
    "base_dir = os.path.join('..', 'data', 'images_original_inception_resnet_v2_200x150_splitted')\n",
    "train_dir = os.path.join(base_dir, 'training')\n",
    "valid_dir = os.path.join(base_dir, 'validation')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_images_array(paths: list[str]) -> np.ndarray:\n",
    "    rows = []\n",
    "    rescale = keras.layers.Rescaling(1./255)\n",
    "\n",
    "    for path in paths:\n",
    "        with PIL.Image.open(path) as image:\n",
    "            image_array = np.asarray(image)\n",
    "            rescaled_image = rescale(image_array)\n",
    "            rows.append(rescaled_image)\n",
    "\n",
    "    return np.array(rows)\n",
    "\n",
    "\n",
    "train_paths = get_paths(train_dir)\n",
    "valid_paths = get_paths(valid_dir)\n",
    "X_train = get_images_array(train_paths)\n",
    "X_valid = get_images_array(valid_paths)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "SMALLER_WIDTH = 600 // 3\n",
    "SMALLER_HEIGHT = 450 // 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_names = set(get_names(train_dir))\n",
    "valid_names = set(get_names(valid_dir))\n",
    "metadata_path = os.path.join('..', 'data', 'HAM10000_metadata_ext.csv')\n",
    "data = pd.read_csv(metadata_path).sort_values(by='image_id')\n",
    "relevant_cols = ['left', 'top', 'right', 'bottom']\n",
    "train_df = data[data['image_id'].isin(train_names)].sort_values(by='image_id')[relevant_cols]\n",
    "valid_df = data[data['image_id'].isin(valid_names)].sort_values(by='image_id')[relevant_cols]\n",
    "ys_train = train_df.to_numpy().astype(float)\n",
    "ys_train[:, [0, 2]] /= SMALLER_HEIGHT\n",
    "ys_train[:, [1, 3]] /= SMALLER_WIDTH\n",
    "ys_valid = valid_df.to_numpy().astype(float)\n",
    "ys_valid[:, [0, 2]] /= SMALLER_HEIGHT\n",
    "ys_valid[:, [1, 3]] /= SMALLER_WIDTH"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using simple IOU loss made the model get stuck - it wasn't getting any better or worse. Using CIOU makes the model start from a worse starting point but it's learning. Let's see how it does after 1000 epochs.\n",
    "\n",
    "(Losses implemented after: https://medium.com/analytics-vidhya/different-iou-losses-for-faster-and-accurate-object-detection-3345781e0bf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def iou_metric(y_true: tf.Tensor, y_pred: tf.Tensor) -> float:\n",
    "    y_true = tf.reshape(y_true, [-1])\n",
    "    y_pred = tf.reshape(y_pred, [-1])\n",
    "\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "\n",
    "    return (intersection + 1.0) / (union + 1.0)\n",
    "\n",
    "\n",
    "def iou_loss(y_true: tf.Tensor, y_pred: tf.Tensor) -> float:\n",
    "    return 1 - iou_metric(y_true, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def ciou_metric(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    y_true -- ground truth bounding box, tensor of shape (?, 4), [xmin, ymin, xmax, ymax]\n",
    "    y_pred -- predicted bounding box, tensor of shape (?, 4)\n",
    "\n",
    "    Returns:\n",
    "    ciou_score -- scalar score, tensor of shape ()\n",
    "    \"\"\"\n",
    "\n",
    "    # Bounding box parameters\n",
    "    y_true = tf.reshape(y_true, [-1, 4])\n",
    "    y_pred = tf.reshape(y_pred, [-1, 4])\n",
    "    true_x1, true_y1, true_x2, true_y2 = tf.split(y_true, 4, axis = -1)\n",
    "    pred_x1, pred_y1, pred_x2, pred_y2 = tf.split(y_pred, 4, axis = -1)\n",
    "\n",
    "    # IoU calculation\n",
    "    intersect_w = tf.maximum(0.0, tf.minimum(true_x2, pred_x2) - tf.maximum(true_x1, pred_x1))\n",
    "    intersect_h = tf.maximum(0.0, tf.minimum(true_y2, pred_y2) - tf.maximum(true_y1, pred_y1))\n",
    "    intersection = intersect_w * intersect_h\n",
    "\n",
    "    true_area = (true_x2 - true_x1) * (true_y2 - true_y1)\n",
    "    pred_area = (pred_x2 - pred_x1) * (pred_y2 - pred_y1)\n",
    "    union = true_area + pred_area - intersection\n",
    "\n",
    "    iou = intersection / (union + 1e-9)  # Adding epsilon to avoid division by zero\n",
    "\n",
    "    # Distance between the box centers\n",
    "    true_center_x = (true_x1 + true_x2) / 2\n",
    "    true_center_y = (true_y1 + true_y2) / 2\n",
    "    pred_center_x = (pred_x1 + pred_x2) / 2\n",
    "    pred_center_y = (pred_y1 + pred_y2) / 2\n",
    "\n",
    "    center_distance = tf.square(true_center_x - pred_center_x) + tf.square(true_center_y - pred_center_y)\n",
    "\n",
    "    # Enclosing box\n",
    "    enclose_x1 = tf.minimum(true_x1, pred_x1)\n",
    "    enclose_y1 = tf.minimum(true_y1, pred_y1)\n",
    "    enclose_x2 = tf.maximum(true_x2, pred_x2)\n",
    "    enclose_y2 = tf.maximum(true_y2, pred_y2)\n",
    "    enclose_w = enclose_x2 - enclose_x1\n",
    "    enclose_h = enclose_y2 - enclose_y1\n",
    "\n",
    "    # Ciou term\n",
    "    ciou_term = (1 - iou) + center_distance / (tf.square(enclose_w) + tf.square(enclose_h) + 1e-9)\n",
    "\n",
    "    return 1.0 - tf.reduce_mean(ciou_term)  # Higher value is better\n",
    "\n",
    "\n",
    "def ciou_loss(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    y_true -- ground truth bounding box, tensor of shape (?, 4), [xmin, ymin, xmax, ymax]\n",
    "    y_pred -- predicted bounding box, tensor of shape (?, 4)\n",
    "\n",
    "    Returns:\n",
    "    ciou_loss -- scalar loss, tensor of shape ()\n",
    "    \"\"\"\n",
    "\n",
    "    # Bounding box parameters\n",
    "    y_true = tf.reshape(y_true, [-1, 4])\n",
    "    y_pred = tf.reshape(y_pred, [-1, 4])\n",
    "    true_x1, true_y1, true_x2, true_y2 = tf.split(y_true, 4, axis = -1)\n",
    "    pred_x1, pred_y1, pred_x2, pred_y2 = tf.split(y_pred, 4, axis = -1)\n",
    "\n",
    "    # IoU calculation\n",
    "    intersect_w = tf.maximum(0.0, tf.minimum(true_x2, pred_x2) - tf.maximum(true_x1, pred_x1))\n",
    "    intersect_h = tf.maximum(0.0, tf.minimum(true_y2, pred_y2) - tf.maximum(true_y1, pred_y1))\n",
    "    intersection = intersect_w * intersect_h\n",
    "\n",
    "    true_area = (true_x2 - true_x1) * (true_y2 - true_y1)\n",
    "    pred_area = (pred_x2 - pred_x1) * (pred_y2 - pred_y1)\n",
    "    union = true_area + pred_area - intersection\n",
    "\n",
    "    iou = intersection / (union + 1e-9)  # Adding epsilon to avoid division by zero\n",
    "\n",
    "    # Distance between the box centers\n",
    "    true_center_x = (true_x1 + true_x2) / 2\n",
    "    true_center_y = (true_y1 + true_y2) / 2\n",
    "    pred_center_x = (pred_x1 + pred_x2) / 2\n",
    "    pred_center_y = (pred_y1 + pred_y2) / 2\n",
    "\n",
    "    center_distance = tf.square(true_center_x - pred_center_x) + tf.square(true_center_y - pred_center_y)\n",
    "\n",
    "    # Enclosing box\n",
    "    enclose_x1 = tf.minimum(true_x1, pred_x1)\n",
    "    enclose_y1 = tf.minimum(true_y1, pred_y1)\n",
    "    enclose_x2 = tf.maximum(true_x2, pred_x2)\n",
    "    enclose_y2 = tf.maximum(true_y2, pred_y2)\n",
    "    enclose_w = enclose_x2 - enclose_x1\n",
    "    enclose_h = enclose_y2 - enclose_y1\n",
    "\n",
    "    # Ciou term\n",
    "    ciou_term = (1 - iou) + center_distance / (tf.square(enclose_w) + tf.square(enclose_h) + 1e-9)\n",
    "\n",
    "    return tf.reduce_mean(ciou_term)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def get_model(loss: Callable, metric: Callable) -> keras.Model:\n",
    "    def get_conv_module(prev: keras.layers.Layer, filters: int, kernel_size: int) -> keras.layers.Layer:\n",
    "        x = keras.layers.Conv2D(filters, kernel_size, padding='same', activation='relu')(prev)\n",
    "        x = keras.layers.Conv2D(filters * 2, kernel_size, padding='same', activation='relu')(x)\n",
    "        x = keras.layers.MaxPooling2D()(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    _input = keras.layers.Input(shape=(SMALLER_HEIGHT, SMALLER_WIDTH, 3))\n",
    "    conv_module = get_conv_module(_input, 16, 7)\n",
    "    conv_module = get_conv_module(conv_module, 32, 5)\n",
    "    conv_module = get_conv_module(conv_module, 64, 3)\n",
    "    conv_module = keras.layers.Flatten()(conv_module)\n",
    "    locator_module = keras.layers.Dense(256, activation='relu')(conv_module)\n",
    "    locator_module = keras.layers.Dense(128, activation='relu')(locator_module)\n",
    "    locator_module = keras.layers.Dense(4, activation='sigmoid')(locator_module)\n",
    "\n",
    "    model = keras.Model(_input, locator_module)\n",
    "\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=[metric])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def run_model(model_factory, model_name: str, loss: Callable, metric: Callable):\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_iou_metric', patience=10,\n",
    "                                                   min_delta=1e-6)\n",
    "    model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath='models/' + model_name + '_{epoch}',\n",
    "        save_best_only=True)\n",
    "    tensor_board = keras.callbacks.TensorBoard(log_dir=f'tensor_logs/{model_name}')\n",
    "    model = model_factory(loss, metric)\n",
    "\n",
    "    return model.fit(\n",
    "        X_train,\n",
    "        ys_train,\n",
    "        validation_data=(X_valid, ys_valid),\n",
    "        epochs=50,\n",
    "        batch_size=64,\n",
    "        callbacks=[model_checkpoint, tensor_board])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 150, 200, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 150, 200, 16)      2368      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 150, 200, 32)      25120     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 75, 100, 32)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 75, 100, 32)       25632     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 75, 100, 64)       51264     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 37, 50, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 37, 50, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 37, 50, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 18, 25, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 57600)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               14745856  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,994,436\n",
      "Trainable params: 14,994,436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.5392 - ciou_metric: 0.4617INFO:tensorflow:Assets written to: models\\roi_detection_iou_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\roi_detection_iou_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 38s 232ms/step - loss: 0.5392 - ciou_metric: 0.4617 - val_loss: 0.3963 - val_ciou_metric: 0.6037\n",
      "Epoch 2/50\n",
      "125/126 [============================>.] - ETA: 0s - loss: 0.3782 - ciou_metric: 0.6218INFO:tensorflow:Assets written to: models\\roi_detection_iou_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\roi_detection_iou_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 27s 211ms/step - loss: 0.3780 - ciou_metric: 0.6228 - val_loss: 0.3426 - val_ciou_metric: 0.6578\n",
      "Epoch 3/50\n",
      "125/126 [============================>.] - ETA: 0s - loss: 0.3162 - ciou_metric: 0.6838INFO:tensorflow:Assets written to: models\\roi_detection_iou_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\roi_detection_iou_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 26s 210ms/step - loss: 0.3163 - ciou_metric: 0.6835 - val_loss: 0.3043 - val_ciou_metric: 0.6965\n",
      "Epoch 4/50\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.2852 - ciou_metric: 0.7149INFO:tensorflow:Assets written to: models\\roi_detection_iou_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\roi_detection_iou_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 27s 211ms/step - loss: 0.2852 - ciou_metric: 0.7149 - val_loss: 0.2718 - val_ciou_metric: 0.7289\n",
      "Epoch 5/50\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.2692 - ciou_metric: 0.7306INFO:tensorflow:Assets written to: models\\roi_detection_iou_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\roi_detection_iou_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 26s 208ms/step - loss: 0.2692 - ciou_metric: 0.7306 - val_loss: 0.2544 - val_ciou_metric: 0.7472\n",
      "Epoch 6/50\n",
      "125/126 [============================>.] - ETA: 0s - loss: 0.2510 - ciou_metric: 0.7490INFO:tensorflow:Assets written to: models\\roi_detection_iou_6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\roi_detection_iou_6\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 26s 209ms/step - loss: 0.2509 - ciou_metric: 0.7493 - val_loss: 0.2484 - val_ciou_metric: 0.7535\n",
      "Epoch 7/50\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.2401 - ciou_metric: 0.7602INFO:tensorflow:Assets written to: models\\roi_detection_iou_7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\roi_detection_iou_7\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 26s 207ms/step - loss: 0.2401 - ciou_metric: 0.7602 - val_loss: 0.2462 - val_ciou_metric: 0.7555\n",
      "Epoch 8/50\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.2287 - ciou_metric: 0.7715INFO:tensorflow:Assets written to: models\\roi_detection_iou_8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\roi_detection_iou_8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 26s 207ms/step - loss: 0.2287 - ciou_metric: 0.7715 - val_loss: 0.2428 - val_ciou_metric: 0.7590\n",
      "Epoch 9/50\n",
      "125/126 [============================>.] - ETA: 0s - loss: 0.2221 - ciou_metric: 0.7779INFO:tensorflow:Assets written to: models\\roi_detection_iou_9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\roi_detection_iou_9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 26s 207ms/step - loss: 0.2221 - ciou_metric: 0.7780 - val_loss: 0.2322 - val_ciou_metric: 0.7694\n",
      "Epoch 10/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.2138 - ciou_metric: 0.7859 - val_loss: 0.2465 - val_ciou_metric: 0.7556\n",
      "Epoch 11/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.2116 - ciou_metric: 0.7883 - val_loss: 0.2398 - val_ciou_metric: 0.7614\n",
      "Epoch 12/50\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.2061 - ciou_metric: 0.7936INFO:tensorflow:Assets written to: models\\roi_detection_iou_12\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\roi_detection_iou_12\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 26s 207ms/step - loss: 0.2061 - ciou_metric: 0.7936 - val_loss: 0.2301 - val_ciou_metric: 0.7717\n",
      "Epoch 13/50\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.1983 - ciou_metric: 0.8018INFO:tensorflow:Assets written to: models\\roi_detection_iou_13\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\roi_detection_iou_13\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 26s 207ms/step - loss: 0.1983 - ciou_metric: 0.8018 - val_loss: 0.2234 - val_ciou_metric: 0.7782\n",
      "Epoch 14/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1937 - ciou_metric: 0.8062 - val_loss: 0.2349 - val_ciou_metric: 0.7666\n",
      "Epoch 15/50\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.1929 - ciou_metric: 0.8071INFO:tensorflow:Assets written to: models\\roi_detection_iou_15\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\roi_detection_iou_15\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 26s 209ms/step - loss: 0.1929 - ciou_metric: 0.8071 - val_loss: 0.2209 - val_ciou_metric: 0.7810\n",
      "Epoch 16/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1858 - ciou_metric: 0.8141 - val_loss: 0.2268 - val_ciou_metric: 0.7750\n",
      "Epoch 17/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1809 - ciou_metric: 0.8191 - val_loss: 0.2234 - val_ciou_metric: 0.7782\n",
      "Epoch 18/50\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.1778 - ciou_metric: 0.8222INFO:tensorflow:Assets written to: models\\roi_detection_iou_18\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\roi_detection_iou_18\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 26s 208ms/step - loss: 0.1778 - ciou_metric: 0.8222 - val_loss: 0.2202 - val_ciou_metric: 0.7814\n",
      "Epoch 19/50\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.1759 - ciou_metric: 0.8242 - val_loss: 0.2304 - val_ciou_metric: 0.7712\n",
      "Epoch 20/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1731 - ciou_metric: 0.8273 - val_loss: 0.2230 - val_ciou_metric: 0.7787\n",
      "Epoch 21/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1675 - ciou_metric: 0.8321 - val_loss: 0.2209 - val_ciou_metric: 0.7807\n",
      "Epoch 22/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1649 - ciou_metric: 0.8353 - val_loss: 0.2234 - val_ciou_metric: 0.7783\n",
      "Epoch 23/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1624 - ciou_metric: 0.8374 - val_loss: 0.2216 - val_ciou_metric: 0.7802\n",
      "Epoch 24/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1610 - ciou_metric: 0.8391 - val_loss: 0.2238 - val_ciou_metric: 0.7784\n",
      "Epoch 25/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1572 - ciou_metric: 0.8427 - val_loss: 0.2220 - val_ciou_metric: 0.7796\n",
      "Epoch 26/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1584 - ciou_metric: 0.8415 - val_loss: 0.2374 - val_ciou_metric: 0.7638\n",
      "Epoch 27/50\n",
      "125/126 [============================>.] - ETA: 0s - loss: 0.1543 - ciou_metric: 0.8457INFO:tensorflow:Assets written to: models\\roi_detection_iou_27\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\roi_detection_iou_27\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 26s 208ms/step - loss: 0.1543 - ciou_metric: 0.8455 - val_loss: 0.2196 - val_ciou_metric: 0.7822\n",
      "Epoch 28/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1511 - ciou_metric: 0.8489 - val_loss: 0.2208 - val_ciou_metric: 0.7811\n",
      "Epoch 29/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1490 - ciou_metric: 0.8506 - val_loss: 0.2209 - val_ciou_metric: 0.7810\n",
      "Epoch 30/50\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.1474 - ciou_metric: 0.8524INFO:tensorflow:Assets written to: models\\roi_detection_iou_30\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\roi_detection_iou_30\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 26s 209ms/step - loss: 0.1474 - ciou_metric: 0.8524 - val_loss: 0.2192 - val_ciou_metric: 0.7826\n",
      "Epoch 31/50\n",
      "126/126 [==============================] - 25s 195ms/step - loss: 0.1441 - ciou_metric: 0.8555 - val_loss: 0.2208 - val_ciou_metric: 0.7810\n",
      "Epoch 32/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1434 - ciou_metric: 0.8563 - val_loss: 0.2229 - val_ciou_metric: 0.7789\n",
      "Epoch 33/50\n",
      "126/126 [==============================] - 25s 195ms/step - loss: 0.1429 - ciou_metric: 0.8571 - val_loss: 0.2215 - val_ciou_metric: 0.7802\n",
      "Epoch 34/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1413 - ciou_metric: 0.8589 - val_loss: 0.2217 - val_ciou_metric: 0.7801\n",
      "Epoch 35/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1401 - ciou_metric: 0.8599 - val_loss: 0.2200 - val_ciou_metric: 0.7818\n",
      "Epoch 36/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1394 - ciou_metric: 0.8604 - val_loss: 0.2206 - val_ciou_metric: 0.7811\n",
      "Epoch 37/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1371 - ciou_metric: 0.8627 - val_loss: 0.2192 - val_ciou_metric: 0.7824\n",
      "Epoch 38/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1350 - ciou_metric: 0.8653 - val_loss: 0.2199 - val_ciou_metric: 0.7818\n",
      "Epoch 39/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1340 - ciou_metric: 0.8663 - val_loss: 0.2207 - val_ciou_metric: 0.7809\n",
      "Epoch 40/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1319 - ciou_metric: 0.8682 - val_loss: 0.2217 - val_ciou_metric: 0.7800\n",
      "Epoch 41/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1321 - ciou_metric: 0.8679 - val_loss: 0.2218 - val_ciou_metric: 0.7799\n",
      "Epoch 42/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1322 - ciou_metric: 0.8679 - val_loss: 0.2216 - val_ciou_metric: 0.7802\n",
      "Epoch 43/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1332 - ciou_metric: 0.8667 - val_loss: 0.2217 - val_ciou_metric: 0.7801\n",
      "Epoch 44/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1312 - ciou_metric: 0.8690 - val_loss: 0.2201 - val_ciou_metric: 0.7816\n",
      "Epoch 45/50\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.1297 - ciou_metric: 0.8705 - val_loss: 0.2203 - val_ciou_metric: 0.7813\n",
      "Epoch 46/50\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.1284 - ciou_metric: 0.8716 - val_loss: 0.2195 - val_ciou_metric: 0.7821\n",
      "Epoch 47/50\n",
      "126/126 [==============================] - 25s 201ms/step - loss: 0.1286 - ciou_metric: 0.8713 - val_loss: 0.2215 - val_ciou_metric: 0.7803\n",
      "Epoch 48/50\n",
      "126/126 [==============================] - 25s 195ms/step - loss: 0.1285 - ciou_metric: 0.8716 - val_loss: 0.2197 - val_ciou_metric: 0.7822\n",
      "Epoch 49/50\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.1264 - ciou_metric: 0.8736INFO:tensorflow:Assets written to: models\\roi_detection_iou_49\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\roi_detection_iou_49\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 26s 208ms/step - loss: 0.1264 - ciou_metric: 0.8736 - val_loss: 0.2183 - val_ciou_metric: 0.7835\n",
      "Epoch 50/50\n",
      "126/126 [==============================] - 25s 195ms/step - loss: 0.1268 - ciou_metric: 0.8734 - val_loss: 0.2202 - val_ciou_metric: 0.7817\n"
     ]
    }
   ],
   "source": [
    "history = run_model(get_model, f'roi_detection_iou', ciou_loss, ciou_metric)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
