{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h3>This notebook contains training code of a neural network performing the \"Region of Interest\" (ROI) detection work. Its output will be used at later stages to preprocess images being fed to the actual classifier. ROI NN will detect bounding boxes surrounding lesions and another algorithm will crop the images so that the aspect ratio required by InceptionResNetV2 NN is used.</h3>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import absl.logging\n",
    "import PIL.Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from typing import Callable\n",
    "from tensorflow import keras\n",
    "\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "get_names = lambda root_path: [\n",
    "    file_name.split('.')[0]\n",
    "    for dir_path, _, file_names in os.walk(root_path)\n",
    "    for file_name in file_names\n",
    "]\n",
    "get_paths = lambda path: [f'{os.path.join(root, file)}' for root, dirs, files in os.walk(path) for file in files]\n",
    "base_dir = os.path.join('..', 'data', 'images_original_inception_resnet_v2_200x150_splitted')\n",
    "train_dir = os.path.join(base_dir, 'training')\n",
    "valid_dir = os.path.join(base_dir, 'validation')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_images_array(paths: list[str]) -> np.ndarray:\n",
    "    rows = []\n",
    "    rescale = keras.layers.Rescaling(1./255)\n",
    "\n",
    "    for path in paths:\n",
    "        with PIL.Image.open(path) as image:\n",
    "            image_array = np.asarray(image)\n",
    "            rescaled_image = rescale(image_array)\n",
    "            rows.append(rescaled_image)\n",
    "\n",
    "    return np.array(rows)\n",
    "\n",
    "\n",
    "train_paths = get_paths(train_dir)\n",
    "valid_paths = get_paths(valid_dir)\n",
    "X_train = get_images_array(train_paths)\n",
    "X_valid = get_images_array(valid_paths)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "SMALLER_WIDTH = 600 // 3\n",
    "SMALLER_HEIGHT = 450 // 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_names = set(get_names(train_dir))\n",
    "valid_names = set(get_names(valid_dir))\n",
    "metadata_path = os.path.join('..', 'data', 'HAM10000_metadata_ext.csv')\n",
    "data = pd.read_csv(metadata_path).sort_values(by='image_id')\n",
    "relevant_cols = ['left', 'top', 'right', 'bottom']\n",
    "train_df = data[data['image_id'].isin(train_names)].sort_values(by='image_id')[relevant_cols]\n",
    "valid_df = data[data['image_id'].isin(valid_names)].sort_values(by='image_id')[relevant_cols]\n",
    "ys_train = train_df.to_numpy().astype(float)\n",
    "ys_train[:, [0, 2]] /= SMALLER_HEIGHT\n",
    "ys_train[:, [1, 3]] /= SMALLER_WIDTH\n",
    "ys_valid = valid_df.to_numpy().astype(float)\n",
    "ys_valid[:, [0, 2]] /= SMALLER_HEIGHT\n",
    "ys_valid[:, [1, 3]] /= SMALLER_WIDTH"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using simple IoU loss made the model get stuck - it wasn't getting any better or worse. Using CIoU makes the model start from a worse starting point but it's learning. Let's see how it does after 1000 epochs.\n",
    "\n",
    "Implementation idea: [Medium article](https://medium.com/analytics-vidhya/different-iou-losses-for-faster-and-accurate-object-detection-3345781e0bf)\n",
    "*IoU formulas and more: [Researchgate article](https://www.researchgate.net/figure/CIoU-calculation-conceptualized-The-classification-function-L-cls-only-penalizes-if_fig5_355427005)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def ciou_loss(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    y_true -- ground truth bounding box, tensor of shape (?, 4), [xmin, ymin, xmax, ymax]\n",
    "    y_pred -- predicted bounding box, tensor of shape (?, 4)\n",
    "\n",
    "    Returns:\n",
    "    ciou_loss -- scalar loss, tensor of shape ()\n",
    "    \"\"\"\n",
    "    true_x1, true_y1, true_x2, true_y2 = tf.split(y_true, 4, axis = -1)\n",
    "    pred_x1, pred_y1, pred_x2, pred_y2 = tf.split(y_pred, 4, axis = -1)\n",
    "    # intersection calculation:\n",
    "    # take leftmost x coord and rightmost x coord, subtract to get the width and constraint with\n",
    "    # 0 to avoid negative values, do the same with ys\n",
    "    intersect_w = tf.maximum(0.0, tf.minimum(true_x2, pred_x2) - tf.maximum(true_x1, pred_x1))\n",
    "    intersect_h = tf.maximum(0.0, tf.minimum(true_y2, pred_y2) - tf.maximum(true_y1, pred_y1))\n",
    "    # calculate area\n",
    "    intersection = intersect_w * intersect_h\n",
    "    # calculate areas of the predicted and actual bounding box\n",
    "    # then calculate the union\n",
    "    true_area = (true_x2 - true_x1) * (true_y2 - true_y1)\n",
    "    pred_area = (pred_x2 - pred_x1) * (pred_y2 - pred_y1)\n",
    "    union = true_area + pred_area - intersection\n",
    "    # IoU calculation\n",
    "    iou = intersection / (union + 1e-9)  # Adding epsilon to avoid division by zero\n",
    "    # distance between the box centers\n",
    "    true_center_x = (true_x1 + true_x2) / 2\n",
    "    true_center_y = (true_y1 + true_y2) / 2\n",
    "    pred_center_x = (pred_x1 + pred_x2) / 2\n",
    "    pred_center_y = (pred_y1 + pred_y2) / 2\n",
    "    # from pythagorean theorem - calculate euclidean distance a^2 + b^2 = c^2\n",
    "    # here the distance is still in the square units, because it doesn't matter in this\n",
    "    # context since if z1 < z2 then sqrt(z1) < sqrt(z2)\n",
    "    # we can save some (very little) computation time by omitting the root calculation\n",
    "    center_distance = tf.square(true_center_x - pred_center_x) + tf.square(true_center_y - pred_center_y)\n",
    "    # enclosing box\n",
    "    enclose_x1 = tf.minimum(true_x1, pred_x1)\n",
    "    enclose_y1 = tf.minimum(true_y1, pred_y1)\n",
    "    enclose_x2 = tf.maximum(true_x2, pred_x2)\n",
    "    enclose_y2 = tf.maximum(true_y2, pred_y2)\n",
    "    enclose_w = enclose_x2 - enclose_x1\n",
    "    enclose_h = enclose_y2 - enclose_y1\n",
    "    # CIoU term\n",
    "    ciou_term = (1 - iou) + center_distance / (tf.square(enclose_w) + tf.square(enclose_h) + 1e-9)\n",
    "\n",
    "    return tf.reduce_mean(ciou_term)\n",
    "\n",
    "\n",
    "def ciou_metric(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "    ciou_term = ciou_loss(y_true, y_pred)\n",
    "\n",
    "    return 1.0 - tf.reduce_mean(ciou_term) # higher value is better"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_model(loss: Callable, metric: Callable) -> keras.Model:\n",
    "    def get_conv_module(prev: keras.layers.Layer, filters: int, kernel_size: int) -> keras.layers.Layer:\n",
    "        x = keras.layers.Conv2D(filters, kernel_size, padding='same', activation='relu')(prev)\n",
    "        x = keras.layers.Conv2D(filters * 2, kernel_size, padding='same', activation='relu')(x)\n",
    "        x = keras.layers.MaxPooling2D()(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    _input = keras.layers.Input(shape=(SMALLER_HEIGHT, SMALLER_WIDTH, 3))\n",
    "    conv_module = get_conv_module(_input, 16, 7)\n",
    "    conv_module = get_conv_module(conv_module, 32, 5)\n",
    "    conv_module = get_conv_module(conv_module, 64, 3)\n",
    "    conv_module = keras.layers.Flatten()(conv_module)\n",
    "    locator_module = keras.layers.Dense(512, activation='relu')(conv_module)\n",
    "    locator_module = keras.layers.Dense(256, activation='relu')(locator_module)\n",
    "    locator_module = keras.layers.Dense(128, activation='relu')(locator_module)\n",
    "    locator_module = keras.layers.Dense(4, activation='sigmoid')(locator_module)\n",
    "\n",
    "    model = keras.Model(_input, locator_module)\n",
    "\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=[metric])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def run_model(model_factory, model_name: str, loss: Callable, metric: Callable):\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_iou_metric', patience=10,\n",
    "                                                   min_delta=1e-6)\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                                  patience=5, min_lr=0.001)\n",
    "    model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath='models/' + model_name + '_{epoch}',\n",
    "        save_best_only=True)\n",
    "    tensor_board = keras.callbacks.TensorBoard(log_dir=f'tensor_logs/{model_name}')\n",
    "    model = model_factory(loss, metric)\n",
    "\n",
    "    return model.fit(\n",
    "        X_train,\n",
    "        ys_train,\n",
    "        validation_data=(X_valid, ys_valid),\n",
    "        epochs=500,\n",
    "        batch_size=64,\n",
    "        callbacks=[reduce_lr, model_checkpoint, tensor_board])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 150, 200, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 150, 200, 16)      2368      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 150, 200, 32)      25120     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 75, 100, 32)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 75, 100, 32)       25632     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 75, 100, 64)       51264     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 37, 50, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 37, 50, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 37, 50, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 18, 25, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 57600)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               29491712  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,871,620\n",
      "Trainable params: 29,871,620\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.5283 - ciou_metric: 0.4718INFO:tensorflow:Assets written to: models\\roi_detection_iou_2_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\roi_detection_iou_2_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 38s 234ms/step - loss: 0.5283 - ciou_metric: 0.4718 - val_loss: 0.4519 - val_ciou_metric: 0.5483 - lr: 0.0010\n",
      "Epoch 2/500\n",
      " 32/126 [======>.......................] - ETA: 18s - loss: 0.4696 - ciou_metric: 0.5304"
     ]
    }
   ],
   "source": [
    "history = run_model(get_model, f'roi_detection_iou_2', ciou_loss, ciou_metric)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
