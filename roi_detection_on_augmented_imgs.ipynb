{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h3>This notebook contains training code of a neural network performing the \"Region of Interest\" (ROI) detection work. The NN is trained on cleaned and noisy images. Its output will be used at later stages to preprocess images being fed to the actual classifier. ROI NN will detect bounding boxes surrounding lesions and another algorithm will crop the images so that the aspect ratio required by InceptionResNetV2 NN is used.</h3>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import os\n",
    "import absl.logging\n",
    "import PIL.Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Callable\n",
    "from tensorflow import keras\n",
    "from typing import Tuple\n",
    "\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "get_names = lambda root_path: [\n",
    "    file_name.split('.')[0]\n",
    "    for dir_path, _, file_names in os.walk(root_path)\n",
    "    for file_name in file_names\n",
    "]\n",
    "get_paths = lambda path: [f'{os.path.join(root, file)}' for root, dirs, files in os.walk(path) for file in files]\n",
    "base_dir = os.path.join('..', 'data', 'images_original_inception_resnet_v2_200x150_splitted_with_augmentation')\n",
    "train_dir = os.path.join(base_dir, 'training')\n",
    "valid_dir = os.path.join(base_dir, 'validation')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "SMALLER_WIDTH = 600 // 3\n",
    "SMALLER_HEIGHT = 450 // 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def parse_csv(file_path: str) -> Tuple[pd.Series, np.ndarray]:\n",
    "    df = pd.read_csv(file_path)\n",
    "    filenames = df['filename'].values\n",
    "    x1 = df['x1'].values\n",
    "    y1 = df['y1'].values\n",
    "    x2 = df['x2'].values\n",
    "    y2 = df['y2'].values\n",
    "\n",
    "    return filenames, np.array([x1, y1, x2, y2]).T\n",
    "\n",
    "\n",
    "def process_path(image_path: str, coords: np.ndarray) -> Tuple[tf.Tensor, np.ndarray]:\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "    return img, coords\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(csv_file_path: str, img_dir: str) -> tf.data.Dataset:\n",
    "    image_filenames, coords = parse_csv(csv_file_path)\n",
    "    image_filenames = [img_dir + '/' + fname for fname in image_filenames]\n",
    "\n",
    "    return tf.data.Dataset\\\n",
    "        .from_tensor_slices((image_filenames, coords))\\\n",
    "        .map(process_path)\\\n",
    "        .batch(32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
