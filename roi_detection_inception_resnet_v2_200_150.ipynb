{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import absl.logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Callable, Tuple\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "from functions.ciou import ciou_loss, ciou_metric\n",
    "from functions.loading_data import parse_csv\n",
    "from functions.loading_data import SMALLER_HEIGHT, SMALLER_WIDTH\n",
    "\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "get_names = lambda root_path: [\n",
    "    file_name.split('.')[0]\n",
    "    for dir_path, _, file_names in os.walk(root_path)\n",
    "    for file_name in file_names\n",
    "]\n",
    "get_paths = lambda path: [f'{os.path.join(root, file)}' for root, dirs, files in os.walk(path) for file in files]\n",
    "base_dir = os.path.join('..', 'data', 'images_original_inception_resnet_v2_200x150_splitted_with_augmentation_10p')\n",
    "train_dir = os.path.join(base_dir, 'training')\n",
    "valid_dir = os.path.join(base_dir, 'validation')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def process_path(\n",
    "        image_path: str,\n",
    "        coords: np.ndarray) -> Tuple[tf.Tensor, np.ndarray]:\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "    return img, coords\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(csv_file_path: str, img_dir: str) -> tf.data.Dataset:\n",
    "    image_filenames, coordinates = parse_csv(csv_file_path)\n",
    "    image_filenames = [os.path.join(img_dir, fname) for fname in image_filenames]\n",
    "\n",
    "    return tf.data.Dataset \\\n",
    "        .from_tensor_slices((\n",
    "            image_filenames,\n",
    "            coordinates)) \\\n",
    "        .map(process_path) \\\n",
    "        .batch(64) \\\n",
    "        .shuffle(1024)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_ds = load_and_preprocess_data(os.path.join('..', 'data', 'training_boxes.csv'), train_dir)\n",
    "valid_ds = load_and_preprocess_data(os.path.join('..', 'data', 'validation_boxes.csv'), valid_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def run_multi_attentive_model(\n",
    "        model_factory: Callable,\n",
    "        model_name: str,\n",
    "        loss: Callable,\n",
    "        metric: Callable,\n",
    "        reduction_patience=5,\n",
    "        monitor='val_ciou_metric'):\n",
    "    MIN_DELTA = .001\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor=monitor,\n",
    "        mode='max',\n",
    "        patience=10,\n",
    "        min_delta=MIN_DELTA)\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=monitor,\n",
    "        mode='max',\n",
    "        factor=0.95,\n",
    "        min_delta=MIN_DELTA,\n",
    "        patience=reduction_patience,\n",
    "        min_lr=0.0005,\n",
    "        verbose=1)\n",
    "    model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath='models/' + model_name + '_{epoch}',\n",
    "        save_best_only=True)\n",
    "    tensor_board = keras.callbacks.TensorBoard(log_dir=f'tensor_logs/{model_name}')\n",
    "    model = model_factory(loss, metric)\n",
    "\n",
    "    return model.fit(\n",
    "        train_ds,\n",
    "        validation_data=valid_ds,\n",
    "        epochs=500,\n",
    "        callbacks=[reduce_lr, model_checkpoint, tensor_board, early_stopping])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_baseline_model(loss: Callable, metric: Callable) -> keras.Model:\n",
    "    def get_attention_module(prev: keras.layers.Layer) -> keras.layers.Layer:\n",
    "        gap_layer = keras.layers.GlobalAveragePooling2D()(prev)\n",
    "        gap_layer_res = keras.layers.Reshape((1, 1, 1536))(gap_layer)\n",
    "        dense = keras.layers.Dense(1536, activation='relu')(gap_layer_res)\n",
    "        dense = keras.layers.Dense(1536, activation='softmax')(dense)\n",
    "        mul_layer = keras.layers.Multiply()([prev, dense])\n",
    "\n",
    "        return mul_layer\n",
    "\n",
    "    base_model = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=(SMALLER_HEIGHT, SMALLER_WIDTH, 3))\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    attention_module = get_attention_module(base_model.output)\n",
    "    flat = keras.layers.Flatten()(attention_module)\n",
    "    locator_module = keras.layers.Dense(4608, activation='relu')(flat)\n",
    "    locator_module = keras.layers.Dense(1024, activation='relu')(locator_module)\n",
    "    locator_module = keras.layers.Dense(4, activation='sigmoid')(locator_module)\n",
    "\n",
    "    model = keras.Model(base_model.input, outputs=locator_module)\n",
    "\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=[metric])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1831/1831 [==============================] - ETA: 0s - loss: 0.4995 - ciou_metric: 0.5005INFO:tensorflow:Assets written to: models\\roi_detection_inception_1_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\roi_detection_inception_1_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1831/1831 [==============================] - 394s 185ms/step - loss: 0.4995 - ciou_metric: 0.5005 - val_loss: 0.4624 - val_ciou_metric: 0.5377 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "1452/1831 [======================>.......] - ETA: 51s - loss: 0.4727 - ciou_metric: 0.5273"
     ]
    }
   ],
   "source": [
    "history1 = run_multi_attentive_model(get_baseline_model, f'roi_detection_inception_1', ciou_loss, ciou_metric, 20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
